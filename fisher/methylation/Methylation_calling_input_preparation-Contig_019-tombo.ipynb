{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for running Nanopore methylation calling on NCI\n",
    "\n",
    "This script does the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pull out all aligned fastq for each contig using previously mapped Nanopores reads with Minimap2\n",
    "- pack them up \n",
    "- pull out all corresponding fast5 files and pack them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tarfile #compress fast5\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to define the base dirs\n",
    "DIRS ={}\n",
    "#DIRS['BASE'] = '/home/ap/mock_up/methylation_calling/nanopore' #home computer. hash out later\n",
    "DIRS['BASE'] = '/home/anjuni/methylation_calling/nanopore' #fisher\n",
    "DIRS['BAM_INPUT'] = os.path.join(DIRS['BASE'], 'input', 'minimap2_alignments' )\n",
    "DIRS['FAST5_TOMBO'] = os.path.join(DIRS['BASE'], 'input', 'all_fast5', 'tombo_fast5')\n",
    "DIRS['FAST5_INPUT'] = os.path.join(DIRS['BASE'], 'input', 'all_fast5')\n",
    "DIRS['FASTQ_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_fastq')\n",
    "DIRS['FAST5_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_fast5')\n",
    "DIRS['REF_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_ref')\n",
    "\n",
    "#fix this here for reference\n",
    "DIRS['REF'] = '/home/anjuni/Pst_104_v13_assembly/' # Pst_104E_v13_ph_ctg.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "\n",
    "#to compress the fast5 reads mapping contig 19 to a tar.gz file\n",
    "def make_tarfile(output_filename, file_list):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        count=0\n",
    "        for file in file_list:\n",
    "            tar.add(file, arcname=os.path.basename(file))\n",
    "            count=count+1\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjuni/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "##Get headings\n",
    "\n",
    "seq_sum_albacore_fh = os.path.join(DIRS['FAST5_INPUT'], 'albacore_fastq/Pst79_run1-4_1d_sequencing_summary.txt')\n",
    "#only read in the first two columns instead of everything (file name and read ID)\n",
    "seq_sum_df = pd.read_csv(seq_sum_albacore_fh, sep='\\t')\n",
    "\n",
    "#reduce the size of the seq_sum dataframe to only contain the filename and read_id column thats all we need\n",
    "small_df = seq_sum_df.iloc[:, [0,1]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_sum_df.head # check if it shows the file name and read ID only. (shows all heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>read_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rsb0001410_20170719_FAH05512_MN21513_mux_scan_...</td>\n",
       "      <td>12756ced-c758-42f7-a359-ba477a20b3a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rsb0001410_20170719_FAH05512_MN21513_mux_scan_...</td>\n",
       "      <td>15749e40-174c-4bd3-9341-8cb37fde491b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rsb0001410_20170719_FAH05512_MN21513_mux_scan_...</td>\n",
       "      <td>23703e5f-144e-405b-aba1-b50ce853ecd9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rsb0001410_20170719_FAH05512_MN21513_mux_scan_...</td>\n",
       "      <td>24dd4f66-0a77-4a45-8b5f-8beb2d1576b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rsb0001410_20170719_FAH05512_MN21513_mux_scan_...</td>\n",
       "      <td>2f4921ba-e9a3-44da-90d0-53815af5fcd7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  rsb0001410_20170719_FAH05512_MN21513_mux_scan_...   \n",
       "1  rsb0001410_20170719_FAH05512_MN21513_mux_scan_...   \n",
       "2  rsb0001410_20170719_FAH05512_MN21513_mux_scan_...   \n",
       "3  rsb0001410_20170719_FAH05512_MN21513_mux_scan_...   \n",
       "4  rsb0001410_20170719_FAH05512_MN21513_mux_scan_...   \n",
       "\n",
       "                                read_id  \n",
       "0  12756ced-c758-42f7-a359-ba477a20b3a1  \n",
       "1  15749e40-174c-4bd3-9341-8cb37fde491b  \n",
       "2  23703e5f-144e-405b-aba1-b50ce853ecd9  \n",
       "3  24dd4f66-0a77-4a45-8b5f-8beb2d1576b0  \n",
       "4  2f4921ba-e9a3-44da-90d0-53815af5fcd7  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df.head() #check format of dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#make second dataframe with read_id first and filename second\n",
    "columnsTitles=[\"read_id\",\"filename\"]\n",
    "df2=small_df.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.to_csv(path_or_buf=os.path.join(DIRS['FASTQ_OUT'], 'read_id_to_fast5'), sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# df2.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# not using this because usign original fastq\n",
    "!python /home/anjuni/scripts/Basecalling-comparison/fix_read_names.py {os.path.join(DIRS['FASTQ_OUT'], 'pcontig_019_aln.fastq')} {os.path.join(DIRS['FASTQ_OUT'], 'read_id_to_fast5')} | gzip > {os.path.join(DIRS['FASTQ_OUT'], 'output_reads.fastq.gz')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick chech if directories exist\n",
    "for value in DIRS.values():\n",
    "    if not os.path.exists(value):\n",
    "        print('%s does not exist' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make file paths for BAM files and reference genome\n",
    "\n",
    "#we generated the BAM file handle (file path)\n",
    "bam_pass_fh = os.path.join(DIRS['BAM_INPUT'], 'Pst79_run1-4_1d_pass.minimap2.out.bam')\n",
    "bam_fail_fh = os.path.join(DIRS['BAM_INPUT'], 'Pst79_run1-4_1d_fail.minimap2.out.bam')\n",
    "\n",
    "#make a list of paths for BAM files to get mapped reads (for all 4 runs)\n",
    "bam_fh_list = [os.path.join(DIRS['BAM_INPUT'], x) for x in os.listdir(DIRS['BAM_INPUT']) if x.endswith('.bam')]\n",
    "\n",
    "######fix this here for reference. use the same as for mapping the long reads\n",
    "reference_fh = os.path.join(DIRS['REF'], 'Pst_104E_v13_ph_ctg.fa')\n",
    "\n",
    "split_reference_fh = os.path.join(DIRS['REF_OUT'], 'tombo_pcontig_019.fasta') #output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bam_fh_list) #check file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pst79_run1-4_1d_fail.minimap2.out.bam\n",
      "Pst79_run1-4_1d_pass.minimap2.out.bam\n",
      "Pst79_run1-4_1d_pass.minimap2.out.bam.bai\n",
      "Pst79_run1-4_1d_fail.minimap2.out.bam.bai\n"
     ]
    }
   ],
   "source": [
    "#just an example to loop over content of a folder\n",
    "for x in os.listdir(DIRS['BAM_INPUT']):\n",
    "    if x.endswith('.bam') or x.endswith('.bai'):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bam_fh_list) #check for all BAM files\n",
    "#print(split_reference_fh) #check path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we 'read' in an bam file. Really we generated an AlignmentFile object \n",
    "bam_pass_file = pysam.AlignmentFile(bam_pass_fh, \"rb\")\n",
    "bam_fail_file = pysam.AlignmentFile(bam_fail_fh, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file_list = [bam_pass_file, bam_fail_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pysam.libcalignmentfile.AlignmentFile at 0x7f17a3a41f28>,\n",
       " <pysam.libcalignmentfile.AlignmentFile at 0x7f178befa268>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a fasta file with all contig_19 reads in reference genome\n",
    "for seq in  SeqIO.parse(reference_fh, 'fasta'):\n",
    "    if seq.id == 'pcontig_019':\n",
    "        SeqIO.write(seq, split_reference_fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the reads (not fastq) for contig_19 from the BAM file\n",
    "contig_19_reads_in_bam = []\n",
    "\n",
    "count_fail = 0\n",
    "count_pass = 0\n",
    "\n",
    "for index,bam in enumerate(bam_file_list):\n",
    "    for read in bam.fetch(contig='pcontig_019'):\n",
    "        if index==0:\n",
    "            count_pass = count_pass + 1\n",
    "        else:\n",
    "            count_fail = count_fail + 1\n",
    "        contig_19_reads_in_bam.append(read) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8030"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contig_19_reads_in_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pysam.libcalignedsegment.AlignedSegment at 0x7f178beff4c8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contig_19_reads_in_bam[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of fail reads mapped:2408\n",
      "This is the number of pass reads mapped:5622\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of fail reads mapped:%i\\nThis is the number of pass reads mapped:%i' % (count_fail, count_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this provides the name for all references in the bam file\n",
    "#bam_file.references"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#not using this anymore\n",
    "\n",
    "#the outfile for the fastq files mapping to pcontig_019\n",
    "fastq_out_fh = os.path.join(DIRS['FASTQ_OUT'], 'pcontig_019_aln.fastq')\n",
    "\n",
    "#we generate an new file and write out all the aligned reads in fastq format\n",
    "#we added in an save guard to save out each read only once as it appears that pysam provides some reads in duplicate.\n",
    "saved_reads = []\n",
    "with open(fastq_out_fh, mode='w') as fastq_out:\n",
    "    for read in contig_19_reads_in_bam:\n",
    "        if read.query_name not in saved_reads:\n",
    "            print('@%s' % read.query_name, file=fastq_out)\n",
    "            print('%s' % read.get_forward_sequence(), file=fastq_out)\n",
    "            print('+', file=fastq_out)\n",
    "            print('%s' % read.get_forward_qualities(), file=fastq_out)\n",
    "            saved_reads.append(read.query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_out_fh = os.path.join(DIRS['FASTQ_OUT'], 'pcontig_019_tombo1.fastq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the outfile for the ids of fastqs mapping to pcontig_019\n",
    "read_id_fh = os.path.join(DIRS['FASTQ_OUT'], 'pcontig_019_tombo.read_id')\n",
    "\n",
    "#we generate an new file and write out all the aligned reads in fastq format\n",
    "#we added in an save guard to save out each read only once as it appears that pysam provides some reads in duplicate.\n",
    "saved_reads = []\n",
    "with open(read_id_fh, mode='w') as out:\n",
    "    for read in contig_19_reads_in_bam:\n",
    "        if read.query_name not in saved_reads:\n",
    "            print(read.query_name, file=out)\n",
    "            saved_reads.append(read.query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "albacore_fastq_fh = os.path.join('/home/anjuni/methylation_calling/nanopore/input/all_fastq/albacore_fastq', 'Pst79_run1-4_1d_all.fastq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbmap_DIR = '/home/anjuni/scripts/BBMap/sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -ea -Xmx285828m -cp /home/anjuni/anaconda3/opt/bbmap-37.95/current/ driver.FilterReadsByName in=/home/anjuni/methylation_calling/nanopore/input/all_fastq/albacore_fastq/Pst79_run1-4_1d_all.fastq out=/home/anjuni/methylation_calling/nanopore/input/split_fastq/pcontig_019_tombo1.fastq names=/home/anjuni/methylation_calling/nanopore/input/split_fastq/pcontig_019_tombo.read_id include=t\n",
      "Executing driver.FilterReadsByName [in=/home/anjuni/methylation_calling/nanopore/input/all_fastq/albacore_fastq/Pst79_run1-4_1d_all.fastq, out=/home/anjuni/methylation_calling/nanopore/input/split_fastq/pcontig_019_tombo1.fastq, names=/home/anjuni/methylation_calling/nanopore/input/split_fastq/pcontig_019_tombo.read_id, include=t]\n",
      "\n",
      "Input is being processed as unpaired\n",
      "Time:               95.614 seconds.\n",
      "Reads Processed:    1095024 \t11.45k reads/sec\n",
      "Bases Processed:    8055376818 \t84.25m bases/sec\n",
      "Reads Out:          7167\n",
      "Bases Out:          128010080\n"
     ]
    }
   ],
   "source": [
    "#Matching fastq to fast5 note: single-threaded, low memory\n",
    "!filterbyname.sh in={albacore_fastq_fh} out={fastq_out_fh} names={read_id_fh} include=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest alinged read to contig_19 is 130111 long\n"
     ]
    }
   ],
   "source": [
    "#we briefly check the longest aligned read\n",
    "max_len = 0\n",
    "with pysam.FastxFile(fastq_out_fh) as fh:\n",
    "    for entry in fh:\n",
    "        if len(entry.sequence) > max_len:\n",
    "            max_len = len(entry.sequence)\n",
    "print('Longest alinged read to contig_19 is %i long'  % max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX TOMBO FAST5 INPUT PATH WITH ***/**/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Making fast5 files with the same filenames as fastq, for methylation-calling\n",
    "\n",
    "#get all the fast5 filenames for the reads that map to contig 19\n",
    "fast5_names_contig_19 = list(small_df[small_df.read_id.isin(saved_reads)]['filename'])\n",
    "\n",
    "#this looks for fast5s recursively in all the Fast5_input folder\n",
    "all_fast5s = [fn for fn in glob.iglob('%s/**/*.fast5' % DIRS['FAST5_TOMBO'], recursive=True)]\n",
    "\n",
    "#this gets the whole path of the fast5s that map to contig_19\n",
    "fast5s_contig_19_fh = [x for x in all_fast5s if x.split('/')[-1] in fast5_names_contig_19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rsb_u5580079_20170828_FAH05280_MN16968_sequencing_run_Pst79_RSB_OpenDay_Run_4_55730_read_1672_ch_48_strand.fast5'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast5_names_contig_19[7166] #check first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-fb0f899ce325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast5s_contig_19_fh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7166\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fast5s_contig_19_fh[7166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(fast5_names_contig_19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make iteration with all mapped fast5\n",
    "\n",
    "fast5_mapped=[]\n",
    "for x in all_fast5s:\n",
    "    fast5_mapped.append(os.path.join(DIRS[\"FAST5_OUT\"],'pcontig_019_aln_fast5.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "### tarzip the mapped fast5 and move to outfolder\n",
    "fast5_mapped = os.path.join(DIRS[\"FAST5_OUT\"],'pcontig_019_tombo_fast5.tar.gz')\n",
    "make_tarfile(fast5_mapped, fast5s_contig_19_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checks\n",
    "\n",
    "#format of fastq BAM files mapped to contig_19\n",
    "read_1 = contig_19_reads[0]\n",
    "\n",
    "#seq_sum_df.columns # to find name column\n",
    "\n",
    "#show the last line (???)\n",
    "seq_sum_df[seq_sum_df.read_id == read_1.query_name]['filename'].to_string().split(' ')[-1]\n",
    "\n",
    "\n",
    "test_fastq = pysam.FastxFile(fastq_out_fh) #BAM file fastq mapping to contig_19\n",
    "test_fastq.close()\n",
    "\n",
    "fastq_out.write(read_1.header) # (???)\n",
    "\n",
    "\n",
    "#Using methods to show fastq lines for fast5\n",
    "#read_1.header #header (???)\n",
    "\n",
    "#read_1.qname #deprecated template name (line 1)\n",
    "#read_1.query_name #template name (line 1)\n",
    "\n",
    "#read_1.seq #deprecated read fastq seq\n",
    "#read_1.query_sequence #read fastq sequence\n",
    "#read_1.query #aligned sequence (line 2)\n",
    "\n",
    "#read_1.qual #quality score\n",
    "#read_1.qqual #alignment quality score (line 4)\n",
    "\n",
    "len(read_1.query) == len(read_1.qqual) #seq and quality score are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
