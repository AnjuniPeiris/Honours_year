{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for running Nanopore methylation calling on NCI\n",
    "\n",
    "This script does the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pull out all aligned fastq for each contig using previously mapped Nanopores reads with Minimap2\n",
    "- pack them up \n",
    "- pull out all corresponding fast5 files and pack them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tarfile #compress fast5\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to define the base dirs\n",
    "DIRS ={}\n",
    "#DIRS['BASE'] = '/home/ap/mock_up/methylation_calling/nanopore' #home computer. hash out later\n",
    "DIRS['BASE'] = '/home/anjuni/methylation_calling/nanopore' #fisher\n",
    "DIRS['BAM_INPUT'] = os.path.join(DIRS['BASE'], 'input', 'minimap2_alignments' )\n",
    "DIRS['FAST5_INPUT'] = os.path.join(DIRS['BASE'], 'input', 'all_fast5') #fix for all runs and copy from nci to right directory\n",
    "DIRS['FASTQ_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_fastq')\n",
    "DIRS['FAST5_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_fast5')\n",
    "DIRS['REF_OUT'] = os.path.join(DIRS['BASE'], 'input', 'split_ref')\n",
    "#fix this here for reference\n",
    "DIRS['REF'] = '/home/anjuni/Pst_104_v13_assembly/' # Pst_104E_v13_ph_ctg.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "\n",
    "#to compress the fast5 reads mapping contig 19 to a tar.gz file\n",
    "def make_tarfile(output_filename, file_list):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        for file in file_list:\n",
    "            tar.add(file, arcname=os.path.basename(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjuni/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "##Get headings\n",
    "\n",
    "seq_sum_albacore_fh = os.path.join(DIRS['FAST5_INPUT'], 'albacore_fastq/Pst79_run1-4_1d_sequencing_summary.txt')\n",
    "#only read in the first two columns instead of everything (file name and read ID)\n",
    "seq_sum_df = pd.read_csv(seq_sum_albacore_fh, sep='\\t')\n",
    "\n",
    "#reduce the size of the seq_sum dataframe to only contain the filename and read_id column thats all we need\n",
    "small_df = seq_sum_df.iloc[:, [0,1]].copy()\n",
    "\n",
    "#small_df.head() #check format of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_sum_df.head # check if it shows the file name and read ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick chech if directories exist\n",
    "for value in DIRS.values():\n",
    "    if not os.path.exists(value):\n",
    "        print('%s does not exist' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make file paths for BAM files and reference genome\n",
    "\n",
    "#we generated the BAM file handle (file path)\n",
    "bam_pass_fh = os.path.join(DIRS['BAM_INPUT'], 'Pst79_run1-4_1d_pass.minimap2.out.bam')\n",
    "bam_fail_fh = os.path.join(DIRS['BAM_INPUT'], 'Pst79_run1-4_1d_fail.minimap2.out.bam')\n",
    "\n",
    "#make a list of paths for BAM files to get mapped reads (for all 4 runs)\n",
    "bam_fh_list = [os.path.join(DIRS['BAM_INPUT'], x) for x in os.listdir(DIRS['BAM_INPUT']) if x.endswith('.bam')]\n",
    "\n",
    "######fix this here for reference. use the same as for mapping the long reads\n",
    "reference_fh = os.path.join(DIRS['REF'], 'Pst_104E_v13_ph_ctg.fa')\n",
    "\n",
    "split_reference_fh = os.path.join(DIRS['REF_OUT'], 'ref_pcontig_019.fasta') #output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bam_fh_list) #check file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pst79_run1-4_1d_fail.minimap2.out.bam\n",
      "Pst79_run1-4_1d_pass.minimap2.out.bam\n",
      "Pst79_run1-4_1d_pass.minimap2.out.bam.bai\n",
      "Pst79_run1-4_1d_fail.minimap2.out.bam.bai\n"
     ]
    }
   ],
   "source": [
    "#just an example to loop over content of a folder\n",
    "for x in os.listdir(DIRS['BAM_INPUT']):\n",
    "    if x.endswith('.bam') or x.endswith('.bai'):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bam_fh_list) #check for all BAM files\n",
    "#print(split_reference_fh) #check path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we 'read' in an bam file. Really we generated an AlignmentFile object \n",
    "bam_pass_file = pysam.AlignmentFile(bam_pass_fh, \"rb\")\n",
    "bam_fail_file = pysam.AlignmentFile(bam_fail_fh, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file_list = [bam_pass_file, bam_fail_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pysam.libcalignmentfile.AlignmentFile at 0x7f876e816e18>,\n",
       " <pysam.libcalignmentfile.AlignmentFile at 0x7f876e816f28>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a fasta file with all contig_19 reads in reference genome\n",
    "for seq in  SeqIO.parse(reference_fh, 'fasta'):\n",
    "    if seq.id == 'pcontig_019':\n",
    "        SeqIO.write(seq, split_reference_fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the reads (not fastq) for contig_19 from the BAM file\n",
    "contig_19_reads_in_bam = []\n",
    "\n",
    "count_fail = 0\n",
    "count_pass = 0\n",
    "\n",
    "for index,bam in enumerate(bam_file_list):\n",
    "    for read in bam.fetch(contig='pcontig_019'):\n",
    "        if index==0:\n",
    "            count_pass = count_pass + 1\n",
    "        else:\n",
    "            count_fail = count_fail + 1\n",
    "        contig_19_reads_in_bam.append(read) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8030"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contig_19_reads_in_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of fail reads mapped:2408\n",
      "This is the number of pass reads mapped:5622\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of fail reads mapped:%i\\nThis is the number of pass reads mapped:%i' % (count_fail, count_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this provides the name for all references in the bam file\n",
    "#bam_file.references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the outfile for the fastq files mapping to pcontig_019\n",
    "fastq_out_fh = os.path.join(DIRS['FASTQ_OUT'], 'pcontig_019_aln.fastq')\n",
    "\n",
    "#we generate an new file and write out all the aligned reads in fastq format\n",
    "#we added in an save guard to save out each read only once as it appears that pysam provides some reads in duplicate.\n",
    "saved_reads = []\n",
    "with open(fastq_out_fh, mode='w') as fastq_out:\n",
    "    for read in contig_19_reads_in_bam:\n",
    "        if read.query_name not in saved_reads:\n",
    "            print('@%s' % read.query_name, file=fastq_out)\n",
    "            print('%s' % read.query, file=fastq_out)\n",
    "            print('+', file=fastq_out)\n",
    "            print('%s' % read.qqual, file=fastq_out)\n",
    "            saved_reads.append(read.query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest alinged read to contig_19 is 76993 long\n"
     ]
    }
   ],
   "source": [
    "#we briefly check the longest aligned read\n",
    "max_lenght = 0\n",
    "with pysam.FastxFile(fastq_out_fh) as fh:\n",
    "    for entry in fh:\n",
    "        if len(entry.sequence) > max_lenght:\n",
    "            max_lenght = len(entry.sequence)\n",
    "print('Longest alinged read to contig_19 is %i long'  % max_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Making fast5 files with the same filenames as fastq, for methylation-calling\n",
    "\n",
    "#get all the fast5 filenames for the reads that map to contig 19\n",
    "fast5_names_contig_19 = list(small_df[small_df.read_id.isin(saved_reads)]['filename'])\n",
    "\n",
    "#this looks for fast5s recursively in all the Fast5_input folder\n",
    "all_fast5s = [fn for fn in glob.iglob('%s/**/*.fast5' % DIRS['FAST5_INPUT'], recursive=True)]\n",
    "\n",
    "#this gets the whole path of the fast5s that map to contig_19\n",
    "fast5s_contig_19_fh = [x for x in all_fast5s if x.split('/')[-1] in fast5_names_contig_19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast5_names_contig_19[0] #check first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fast5s_contig_19_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fast5_names_contig_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#make iteration with all mapped fast5\n",
    "\n",
    "fast5_mapped=[]\n",
    "for x in all_fast5s:\n",
    "    fast5_mapped.append(os.path.join(DIRS[\"FAST5_OUT\"],'pcontig_019_aln_fast5.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contig_19_fast5s_fh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cdd4a0230320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### tarzip the mapped fast5 and move to outfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfast5_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FAST5_OUT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pcontig_019_aln_fast5.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmake_tarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast5_mapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_19_fast5s_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'contig_19_fast5s_fh' is not defined"
     ]
    }
   ],
   "source": [
    "### tarzip the mapped fast5 and move to outfolder\n",
    "fast5_mapped = os.path.join(DIRS[\"FAST5_OUT\"],'pcontig_019_aln_fast5.tar.gz')\n",
    "make_tarfile(fast5_mapped, fast5s_contig_19_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checks\n",
    "\n",
    "#format of fastq BAM files mapped to contig_19\n",
    "read_1 = contig_19_reads[0]\n",
    "\n",
    "#seq_sum_df.columns # to find name column\n",
    "\n",
    "#show the last line (???)\n",
    "seq_sum_df[seq_sum_df.read_id == read_1.query_name]['filename'].to_string().split(' ')[-1]\n",
    "\n",
    "\n",
    "test_fastq = pysam.FastxFile(fastq_out_fh) #BAM file fastq mapping to contig_19\n",
    "test_fastq.close()\n",
    "\n",
    "fastq_out.write(read_1.header) # (???)\n",
    "\n",
    "\n",
    "#Using methods to show fastq lines for fast5\n",
    "#read_1.header #header (???)\n",
    "\n",
    "#read_1.qname #deprecated template name (line 1)\n",
    "#read_1.query_name #template name (line 1)\n",
    "\n",
    "#read_1.seq #deprecated read fastq seq\n",
    "#read_1.query_sequence #read fastq sequence\n",
    "#read_1.query #aligned sequence (line 2)\n",
    "\n",
    "#read_1.qual #quality score\n",
    "#read_1.qqual #alignment quality score (line 4)\n",
    "\n",
    "len(read_1.query) == len(read_1.qqual) #seq and quality score are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
