{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\"> Prepare TE and gene model annotation files. </span>\n",
    "\n",
    "This notebook combines the TE model data with the gene model data, as they were previously separated.\n",
    "\n",
    "1. Get the annotations file (.gff3) and the reference file (ctg.fa)\n",
    "2. SeqIO.parse through reference genome and get a list of all contig names.\n",
    "3. Make pandas dataframe of annotation file.\n",
    "4. Subset dataframe to column 0 that only has values in list of contig names from reference file.\n",
    "5. Use \"to.csv(\\t)\" to convert the subset to a tab-separated GFF file.\n",
    "6. Cat this subset GFF file of TE data to the gene data GFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import glob\n",
    "import wiggelen\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to define the base dirs\n",
    "DIRS ={}\n",
    "DIRS['BASE'] =  '../../../../analysis/' # absolute path = '/home/anjuni/analysis/'\n",
    "DIRS['GFF_INPUT'] = os.path.join(DIRS['BASE'], 'annotations')\n",
    "DIRS['GFF_OUT'] = os.path.join(DIRS['BASE'], 'output')\n",
    "DIRS['REF'] = '../../../../Pst_104_v13_assembly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../analysis/\n",
      "../../../../analysis/annotations\n",
      "../../../../analysis/output\n",
      "../../../../Pst_104_v13_assembly/\n"
     ]
    }
   ],
   "source": [
    "#Quick chech if directories exist\n",
    "for value in DIRS.values():\n",
    "    if not os.path.exists(value):\n",
    "        print('%s does not exist' % value)\n",
    "    else:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make filepaths\n",
    "gff_file_list = [fn for fn in glob.iglob('%s/*.gff3' % DIRS['GFF_INPUT'], recursive=True)]\n",
    "ref_fh = os.path.join(DIRS['REF'], 'Pst_104E_v13_ph_ctg.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../analysis/annotations/Pst_104E_v13_p_ctg.repeatgenesLT.gff3\n",
      "../../../../analysis/annotations/Pst_104E_v13_h_ctg.repeatgenesLT.gff3\n",
      "../../../../analysis/annotations/Pst_104E_v13_p_ctg.anno.gff3\n",
      "../../../../analysis/annotations/Pst_104E_v13_h_ctg.anno.gff3\n"
     ]
    }
   ],
   "source": [
    "#Check that the list works\n",
    "print(*gff_file_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of all contig names\n",
    "for seq.id in  SeqIO.parse(ref_fh, 'fasta'):\n",
    "    if seq.id #is not in the list:\n",
    "    #append to the list\n",
    "        SeqIO.write(seq, split_reference_fh, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5mC_hc_nanopolish_sorted\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5mC_hc_nanopolish_sorted\n",
      "5mC_tombo_sorted\n",
      "5mC_nanopolish_sorted\n",
      "6mA_tombo_sorted\n",
      "6mA_smrtlink_sorted\n",
      "6mA_prob_smrtlink_sorted\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
