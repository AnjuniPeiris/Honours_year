{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\"> featureCounts test. </span>\n",
    "\n",
    "This notebook makes featureCounts files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import numpy # needed for last few bedtools functions\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "featureCounts: unrecognized option '--help'\n",
      "\n",
      "Version 1.6.2\n",
      "\n",
      "Usage: featureCounts [options] -a <annotation_file> -o <output_file> input_file1 [input_file2] ... \n",
      "\n",
      "## Mandatory arguments:\n",
      "\n",
      "  -a <string>         Name of an annotation file. GTF/GFF format by default. See\n",
      "                      -F option for more format information. Inbuilt annotations\n",
      "                      (SAF format) is available in 'annotation' directory of the\n",
      "                      package. Gzipped file is also accepted.\n",
      "\n",
      "  -o <string>         Name of the output file including read counts. A separate\n",
      "                      file including summary statistics of counting results is\n",
      "                      also included in the output ('<string>.summary')\n",
      "\n",
      "  input_file1 [input_file2] ...   A list of SAM or BAM format files. They can be\n",
      "                      either name or location sorted. If no files provided,\n",
      "                      <stdin> input is expected. Location-sorted paired-end reads\n",
      "                      are automatically sorted by read names.\n",
      "\n",
      "## Optional arguments:\n",
      "# Annotation\n",
      "\n",
      "  -F <string>         Specify format of the provided annotation file. Acceptable\n",
      "                      formats include 'GTF' (or compatible GFF format) and\n",
      "                      'SAF'. 'GTF' by default.  For SAF format, please refer to\n",
      "                      Users Guide.\n",
      "\n",
      "  -t <string>         Specify feature type in GTF annotation. 'exon' by \n",
      "                      default. Features used for read counting will be \n",
      "                      extracted from annotation using the provided value.\n",
      "\n",
      "  -g <string>         Specify attribute type in GTF annotation. 'gene_id' by \n",
      "                      default. Meta-features used for read counting will be \n",
      "                      extracted from annotation using the provided value.\n",
      "\n",
      "  --extraAttributes   Extract extra attribute types from the provided GTF\n",
      "                      annotation and include them in the counting output. These\n",
      "                      attribute types will not be used to group features. If\n",
      "                      more than one attribute type is provided they should be\n",
      "                      separated by comma.\n",
      "\n",
      "  -A <string>         Provide a chromosome name alias file to match chr names in\n",
      "                      annotation with those in the reads. This should be a two-\n",
      "                      column comma-delimited text file. Its first column should\n",
      "                      include chr names in the annotation and its second column\n",
      "                      should include chr names in the reads. Chr names are case\n",
      "                      sensitive. No column header should be included in the\n",
      "                      file.\n",
      "\n",
      "# Level of summarization\n",
      "\n",
      "  -f                  Perform read counting at feature level (eg. counting \n",
      "                      reads for exons rather than genes).\n",
      "\n",
      "# Overlap between reads and features\n",
      "\n",
      "  -O                  Assign reads to all their overlapping meta-features (or \n",
      "                      features if -f is specified).\n",
      "\n",
      "  --minOverlap <int>  Minimum number of overlapping bases in a read that is\n",
      "                      required for read assignment. 1 by default. Number of\n",
      "                      overlapping bases is counted from both reads if paired\n",
      "                      end. If a negative value is provided, then a gap of up\n",
      "                      to specified size will be allowed between read and the\n",
      "                      feature that the read is assigned to.\n",
      "\n",
      "  --fracOverlap <float> Minimum fraction of overlapping bases in a read that is\n",
      "                      required for read assignment. Value should be within range\n",
      "                      [0,1]. 0 by default. Number of overlapping bases is\n",
      "                      counted from both reads if paired end. Both this option\n",
      "                      and '--minOverlap' option need to be satisfied for read\n",
      "                      assignment.\n",
      "\n",
      "  --fracOverlapFeature <float> Minimum fraction of overlapping bases in a\n",
      "                      feature that is required for read assignment. Value\n",
      "                      should be within range [0,1]. 0 by default.\n",
      "\n",
      "  --largestOverlap    Assign reads to a meta-feature/feature that has the \n",
      "                      largest number of overlapping bases.\n",
      "\n",
      "  --nonOverlap <int>  Maximum number of non-overlapping bases in a read (or a\n",
      "                      read pair) that is allowed when being assigned to a\n",
      "                      feature. No limit is set by default.\n",
      "\n",
      "  --nonOverlapFeature <int> Maximum number of non-overlapping bases in a feature\n",
      "                      that is allowed in read assignment. No limit is set by\n",
      "                      default.\n",
      "\n",
      "  --readExtension5 <int> Reads are extended upstream by <int> bases from their\n",
      "                      5' end.\n",
      "\n",
      "  --readExtension3 <int> Reads are extended upstream by <int> bases from their\n",
      "                      3' end.\n",
      "\n",
      "  --read2pos <5:3>    Reduce reads to their 5' most base or 3' most base. Read\n",
      "                      counting is then performed based on the single base the \n",
      "                      read is reduced to.\n",
      "\n",
      "# Multi-mapping reads\n",
      "\n",
      "  -M                  Multi-mapping reads will also be counted. For a multi-\n",
      "                      mapping read, all its reported alignments will be \n",
      "                      counted. The 'NH' tag in BAM/SAM input is used to detect \n",
      "                      multi-mapping reads.\n",
      "\n",
      "# Fractional counting\n",
      "\n",
      "  --fraction          Assign fractional counts to features. This option must\n",
      "                      be used together with '-M' or '-O' or both. When '-M' is\n",
      "                      specified, each reported alignment from a multi-mapping\n",
      "                      read (identified via 'NH' tag) will carry a fractional\n",
      "                      count of 1/x, instead of 1 (one), where x is the total\n",
      "                      number of alignments reported for the same read. When '-O'\n",
      "                      is specified, each overlapping feature will receive a\n",
      "                      fractional count of 1/y, where y is the total number of\n",
      "                      features overlapping with the read. When both '-M' and\n",
      "                      '-O' are specified, each alignment will carry a fractional\n",
      "                      count of 1/(x*y).\n",
      "\n",
      "# Read filtering\n",
      "\n",
      "  -Q <int>            The minimum mapping quality score a read must satisfy in\n",
      "                      order to be counted. For paired-end reads, at least one\n",
      "                      end should satisfy this criteria. 0 by default.\n",
      "\n",
      "  --splitOnly         Count split alignments only (ie. alignments with CIGAR\n",
      "                      string containing 'N'). An example of split alignments is\n",
      "                      exon-spanning reads in RNA-seq data.\n",
      "\n",
      "  --nonSplitOnly      If specified, only non-split alignments (CIGAR strings do\n",
      "                      not contain letter 'N') will be counted. All the other\n",
      "                      alignments will be ignored.\n",
      "\n",
      "  --primary           Count primary alignments only. Primary alignments are \n",
      "                      identified using bit 0x100 in SAM/BAM FLAG field.\n",
      "\n",
      "  --ignoreDup         Ignore duplicate reads in read counting. Duplicate reads \n",
      "                      are identified using bit Ox400 in BAM/SAM FLAG field. The \n",
      "                      whole read pair is ignored if one of the reads is a \n",
      "                      duplicate read for paired end data.\n",
      "\n",
      "# Strandness\n",
      "\n",
      "  -s <int or string>  Perform strand-specific read counting. A single integer\n",
      "                      value (applied to all input files) or a string of comma-\n",
      "                      separated values (applied to each corresponding input\n",
      "                      file) should be provided. Possible values include:\n",
      "                      0 (unstranded), 1 (stranded) and 2 (reversely stranded).\n",
      "                      Default value is 0 (ie. unstranded read counting carried\n",
      "                      out for all input files).\n",
      "\n",
      "# Exon-exon junctions\n",
      "\n",
      "  -J                  Count number of reads supporting each exon-exon junction.\n",
      "                      Junctions were identified from those exon-spanning reads\n",
      "                      in the input (containing 'N' in CIGAR string). Counting\n",
      "                      results are saved to a file named '<output_file>.jcounts'\n",
      "\n",
      "  -G <string>         Provide the name of a FASTA-format file that contains the\n",
      "                      reference sequences used in read mapping that produced the\n",
      "                      provided SAM/BAM files. This optional argument can be used\n",
      "                      with '-J' option to improve read counting for junctions.\n",
      "\n",
      "# Parameters specific to paired end reads\n",
      "\n",
      "  -p                  If specified, fragments (or templates) will be counted\n",
      "                      instead of reads. This option is only applicable for\n",
      "                      paired-end reads.\n",
      "\n",
      "  -B                  Only count read pairs that have both ends aligned.\n",
      "\n",
      "  -P                  Check validity of paired-end distance when counting read \n",
      "                      pairs. Use -d and -D to set thresholds.\n",
      "\n",
      "  -d <int>            Minimum fragment/template length, 50 by default.\n",
      "\n",
      "  -D <int>            Maximum fragment/template length, 600 by default.\n",
      "\n",
      "  -C                  Do not count read pairs that have their two ends mapping \n",
      "                      to different chromosomes or mapping to same chromosome \n",
      "                      but on different strands.\n",
      "\n",
      "  --donotsort         Do not sort reads in BAM/SAM input. Note that reads from \n",
      "                      the same pair are required to be located next to each \n",
      "                      other in the input.\n",
      "\n",
      "# Number of CPU threads\n",
      "\n",
      "  -T <int>            Number of the threads. 1 by default.\n",
      "\n",
      "# Read groups\n",
      "\n",
      "  --byReadGroup       Assign reads by read group. \"RG\" tag is required to be\n",
      "                      present in the input BAM/SAM files.\n",
      "                      \n",
      "\n",
      "# Long reads\n",
      "\n",
      "  -L                  Count long reads such as Nanopore and PacBio reads. Long\n",
      "                      read counting can only run in one thread and only reads\n",
      "                      (not read-pairs) can be counted. There is no limitation on\n",
      "                      the number of 'M' operations allowed in a CIGAR string in\n",
      "                      long read counting.\n",
      "\n",
      "# Assignment results for each read\n",
      "\n",
      "  -R <format>         Output detailed assignment results for each read or read-\n",
      "                      pair. Results are saved to a file that is in one of the\n",
      "                      following formats: CORE, SAM and BAM. See Users Guide for\n",
      "                      more info about these formats.\n",
      "\n",
      "  --Rpath <string>    Specify a directory to save the detailed assignment\n",
      "                      results. If unspecified, the directory where counting\n",
      "                      results are saved is used.\n",
      "\n",
      "# Miscellaneous\n",
      "\n",
      "  --tmpDir <string>   Directory under which intermediate files are saved (later\n",
      "                      removed). By default, intermediate files will be saved to\n",
      "                      the directory specified in '-o' argument.\n",
      "\n",
      "  --maxMOp <int>      Maximum number of 'M' operations allowed in a CIGAR\n",
      "                      string. 10 by default. Both 'X' and '=' are treated as 'M'\n",
      "                      and adjacent 'M' operations are merged in the CIGAR\n",
      "                      string.\n",
      "\n",
      "  --verbose           Output verbose information for debugging, such as un-\n",
      "                      matched chromosome/contig names.\n",
      "\n",
      "  -v                  Output version of the program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "featureCounts --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to define the base dirs\n",
    "DIRS ={}\n",
    "DIRS['BASE'] = '/home/anjuni/analysis/'\n",
    "DIRS['PH_BAM_INPUT'] = os.path.join(DIRS['BASE'], 'stringtie/Pst_104E_v13_ph')\n",
    "DIRS['H_BAM_INPUT'] = os.path.join(DIRS['BASE'], 'stringtie/Pst_104E_v13_h')\n",
    "DIRS['P_BAM_INPUT'] = os.path.join(DIRS['BASE'], 'stringtie/Pst_104E_v13_p')\n",
    "DIRS['GFF_INPUT'] = os.path.join(DIRS['BASE'], 'gff_output')\n",
    "DIRS['REF'] = '/home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick chech if directories exist\n",
    "for value in DIRS.values():\n",
    "    if not os.path.exists(value):\n",
    "        print('%s does not exist' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cd /home/anjuni/analysis/stringtie/Pst_104E_v13_h\n",
      "+ cd /home/anjuni/analysis/stringtie/Pst_104E_v13_h\n",
      "bam=IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out.bam\n",
      "+ bam=IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out.bam\n",
      "anno=/home/anjuni/analysis/gff_output/Pst_104E_v13_h_ctg_combined_sorted_anno.gff3\n",
      "+ anno=/home/anjuni/analysis/gff_output/Pst_104E_v13_h_ctg_combined_sorted_anno.gff3\n",
      "ref=/home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa\n",
      "+ ref=/home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa\n",
      "# for genes\n",
      "featureCounts -T 8 -t gene -g Name -a $anno -G $ref -o Pst_104E_v13_h_counts_gene.txt $bam\n",
      "+ featureCounts -T 8 -t gene -g Name -a /home/anjuni/analysis/gff_output/Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 -G /home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa -o Pst_104E_v13_h_counts_gene.txt IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out.bam\n",
      "\n",
      "        ==========     _____ _    _ ____  _____  ______          _____  \n",
      "        =====         / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "          =====      | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "            ====      \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "              ====    ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "        ==========   |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\n",
      "\t  v1.6.2\n",
      "\n",
      "//========================== featureCounts setting ===========================\\\\\n",
      "||                                                                            ||\n",
      "||             Input files : 1 BAM file                                       ||\n",
      "||                           P IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedB ... ||\n",
      "||                                                                            ||\n",
      "||             Output file : Pst_104E_v13_h_counts_gene.txt                   ||\n",
      "||                 Summary : Pst_104E_v13_h_counts_gene.txt.summary           ||\n",
      "||              Annotation : Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 ... ||\n",
      "||      Dir for temp files : ./                                               ||\n",
      "||                                                                            ||\n",
      "||                 Threads : 8                                                ||\n",
      "||                   Level : meta-feature level                               ||\n",
      "||              Paired-end : no                                               ||\n",
      "||      Multimapping reads : not counted                                      ||\n",
      "|| Multi-overlapping reads : not counted                                      ||\n",
      "||   Min overlapping bases : 1                                                ||\n",
      "||                                                                            ||\n",
      "\\\\===================== http://subread.sourceforge.net/ ======================//\n",
      "\n",
      "//================================= Running ==================================\\\\\n",
      "||                                                                            ||\n",
      "|| Load annotation file Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 ...      ||\n",
      "||    Features : 17199                                                        ||\n",
      "||    Meta-features : 17199                                                   ||\n",
      "||    Chromosomes/contigs : 473                                               ||\n",
      "||                                                                            ||\n",
      "|| Loading FASTA contigs : /home/anjuni/Pst_104_v13_assembly/Pst_104E_v13 ... ||\n",
      "||    475 contigs were loaded                                                 ||\n",
      "||                                                                            ||\n",
      "|| Process BAM file IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out. ... ||\n",
      "||    Paired-end reads are included.                                          ||\n",
      "||    Assign reads to features...                                             ||\n",
      "||    Total reads : 283710                                                    ||\n",
      "||    Successfully assigned reads : 20146 (7.1%)                              ||\n",
      "||    Running time : 0.02 minutes                                             ||\n",
      "||                                                                            ||\n",
      "||                         Read assignment finished.                          ||\n",
      "||                                                                            ||\n",
      "|| Summary of counting results can be found in file \"Pst_104E_v13_h_counts_g  ||\n",
      "|| ene.txt.summary\"                                                           ||\n",
      "||                                                                            ||\n",
      "\\\\===================== http://subread.sourceforge.net/ ======================//\n",
      "\n",
      "# for exons\n",
      "featureCounts -T 8 -t exon -g Parent -a $anno -G $ref -o Pst_104E_v13_h_counts_exon.txt $bam\n",
      "+ featureCounts -T 8 -t exon -g Parent -a /home/anjuni/analysis/gff_output/Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 -G /home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa -o Pst_104E_v13_h_counts_exon.txt IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out.bam\n",
      "\n",
      "        ==========     _____ _    _ ____  _____  ______          _____  \n",
      "        =====         / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "          =====      | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "            ====      \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "              ====    ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "        ==========   |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\n",
      "\t  v1.6.2\n",
      "\n",
      "//========================== featureCounts setting ===========================\\\\\n",
      "||                                                                            ||\n",
      "||             Input files : 1 BAM file                                       ||\n",
      "||                           P IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedB ... ||\n",
      "||                                                                            ||\n",
      "||             Output file : Pst_104E_v13_h_counts_exon.txt                   ||\n",
      "||                 Summary : Pst_104E_v13_h_counts_exon.txt.summary           ||\n",
      "||              Annotation : Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 ... ||\n",
      "||      Dir for temp files : ./                                               ||\n",
      "||                                                                            ||\n",
      "||                 Threads : 8                                                ||\n",
      "||                   Level : meta-feature level                               ||\n",
      "||              Paired-end : no                                               ||\n",
      "||      Multimapping reads : not counted                                      ||\n",
      "|| Multi-overlapping reads : not counted                                      ||\n",
      "||   Min overlapping bases : 1                                                ||\n",
      "||                                                                            ||\n",
      "\\\\===================== http://subread.sourceforge.net/ ======================//\n",
      "\n",
      "//================================= Running ==================================\\\\\n",
      "||                                                                            ||\n",
      "|| Load annotation file Pst_104E_v13_h_ctg_combined_sorted_anno.gff3 ...      ||\n",
      "||    Features : 69681                                                        ||\n",
      "||    Meta-features : 17199                                                   ||\n",
      "||    Chromosomes/contigs : 473                                               ||\n",
      "||                                                                            ||\n",
      "|| Loading FASTA contigs : /home/anjuni/Pst_104_v13_assembly/Pst_104E_v13 ... ||\n",
      "||    475 contigs were loaded                                                 ||\n",
      "||                                                                            ||\n",
      "|| Process BAM file IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out. ... ||\n",
      "||    Paired-end reads are included.                                          ||\n",
      "||    Assign reads to features...                                             ||\n",
      "||    Total reads : 283710                                                    ||\n",
      "||    Successfully assigned reads : 20088 (7.1%)                              ||\n",
      "||    Running time : 0.02 minutes                                             ||\n",
      "||                                                                            ||\n",
      "||                         Read assignment finished.                          ||\n",
      "||                                                                            ||\n",
      "|| Summary of counting results can be found in file \"Pst_104E_v13_h_counts_e  ||\n",
      "|| xon.txt.summary\"                                                           ||\n",
      "||                                                                            ||\n",
      "\\\\===================== http://subread.sourceforge.net/ ======================//\n",
      "\n",
      "\n",
      "# it works\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -vex\n",
    "cd /home/anjuni/analysis/stringtie/Pst_104E_v13_h\n",
    "bam=IT0_DG_6_ACTTGA_L001_R1_001Aligned.sortedByCoord.out.bam\n",
    "anno=/home/anjuni/analysis/gff_output/Pst_104E_v13_h_ctg_combined_sorted_anno.gff3\n",
    "ref=/home/anjuni/Pst_104_v13_assembly/Pst_104E_v13_h_ctg.fa\n",
    "# for genes\n",
    "featureCounts -T 8 -t gene -g Name -a $anno -G $ref -o Pst_104E_v13_h_counts_gene.txt $bam\n",
    "# for exons\n",
    "featureCounts -T 8 -t exon -g Parent -a $anno -G $ref -o Pst_104E_v13_h_counts_exon.txt $bam\n",
    "\n",
    "# it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make filepaths\n",
    "ph_bam_list = [fn for fn in glob.iglob('%s/*.bam' % DIRS['PH_BAM_INPUT'], recursive=True)]\n",
    "ph_Pst_104E_gff = os.path.join(DIRS['GFF_INPUT'], 'Pst_104E_v13_ph_ctg_combined_sorted_anno.gff3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5mC_hc_nanopolish_sorted.bed', '5mC_tombo_sorted.bed', '5mC_nanopolish_sorted.bed', '5mC_hc_tombo_sorted.bed', '6mA_tombo_sorted.bed', '6mA_smrtlink_sorted.bed', '6mA_hc_tombo_sorted.bed', '5mC_overlap.bed', '6mA_prob_smrtlink_sorted.bed']\n"
     ]
    }
   ],
   "source": [
    "# not sure how to use it as it doesn't have absolute path\n",
    "all_bed_files = os.listdir(DIRS['BED_INPUT'])\n",
    "print(all_bed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_hc_nanopolish_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_tombo_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_nanopolish_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_hc_tombo_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_tombo_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_smrtlink_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_hc_tombo_sorted.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_overlap.bed\n",
      "/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_prob_smrtlink_sorted.bed\n"
     ]
    }
   ],
   "source": [
    "#Check that the list works\n",
    "print(*bed_file_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out making a BedT\n",
    "# Setting BedTools objects\n",
    "m5c_hc_nano = BedTool(bed_file_list[0])\n",
    "m5c_tombo = BedTool(bed_file_list[1])\n",
    "m5c_nano = BedTool(bed_file_list[2])\n",
    "m6a_tombo = BedTool(bed_file_list[3])\n",
    "m6a_smrt = BedTool(bed_file_list[4])\n",
    "m6a_prob_smrt = BedTool(bed_file_list[5])\n",
    "anno_ph_gff = BedTool(ph_Pst_104E_gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a dictionary to make a list of bed files\n",
    "BED = {}\n",
    "for file in bed_file_list:\n",
    "    name = (file[63:-4])\n",
    "    bed_file = BedTool(file)\n",
    "    BED[name] = bed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5mC_hc_nanopolish_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_hc_nanopolish_sorted.bed)>,\n",
      " '5mC_hc_tombo_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_hc_tombo_sorted.bed)>,\n",
      " '5mC_nanopolish_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_nanopolish_sorted.bed)>,\n",
      " '5mC_overlap': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_overlap.bed)>,\n",
      " '5mC_tombo_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/5mC_tombo_sorted.bed)>,\n",
      " '6mA_hc_tombo_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_hc_tombo_sorted.bed)>,\n",
      " '6mA_prob_smrtlink_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_prob_smrtlink_sorted.bed)>,\n",
      " '6mA_smrtlink_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_smrtlink_sorted.bed)>,\n",
      " '6mA_tombo_sorted': <BedTool(/home/anjuni/methylation_calling/pacbio/input/sorted_bed_files/6mA_tombo_sorted.bed)>}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(BED) # see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output file handles\n",
    "hc_nano_tombo_m5c = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '5mC_hc_nano_tombo.bed')\n",
    "nano_tombo_m5c = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '5mC_nano_tombo.bed')\n",
    "tombo_hc_nano_m5c = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '5mC_tombo_hc_nano.bed')\n",
    "tombo_nano_5mc = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '5mC_tombo_nano.bed')\n",
    "\n",
    "#for trying to filter the tombo files\n",
    "hc_tombo_m5c = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '5mC_hc_tombo_sorted.bed')\n",
    "hc_tombo_m6a = DIRS['BED_OUT'] = os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', '6mA_hc_tombo_sorted.bed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:crimson\"> Intersections. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/5mC_hc_nano_tombo.bed)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersect the high confidence nanopolish 5mC methylation sites with the tombo ones\n",
    "m5c_hc_nano.intersect(m5c_tombo).saveas(hc_nano_tombo_m5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/5mC_nano_tombo.bed)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersect the low confidence nanopolish 5mC methylation sites with the tombo ones\n",
    "m5c_nano.intersect(m5c_tombo).saveas(nano_tombo_m5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/5mC_tombo_nano.bed)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5c_tombo.intersect(m5c_nano).saveas(tombo_nano_5mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun m5c_tombo.intersect(m5c_hc_nano).saveas(tombo_hc_nano_m5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcontig_000_003\t289\t290\t5mC\t0.071\t+\n",
      " hcontig_000_003\t438\t439\t5mC\t0.048\t+\n",
      " hcontig_000_003\t443\t444\t5mC\t0.048\t+\n",
      " hcontig_000_003\t823\t824\t5mC\t0.091\t+\n",
      " hcontig_000_003\t851\t852\t5mC\t0.071\t+\n",
      " hcontig_000_003\t931\t932\t5mC\t0.071\t+\n",
      " hcontig_000_003\t935\t936\t5mC\t0.071\t+\n",
      " hcontig_000_003\t1004\t1005\t5mC\t0.071\t+\n",
      " hcontig_000_003\t1074\t1075\t5mC\t0.071\t+\n",
      " hcontig_000_003\t1077\t1078\t5mC\t0.071\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "m5c_hc_nano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = gff.intersect(tombo_hc_nano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/gff_tombo_5mC.bed)>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.saveas(os.path.join(DIRS['BASE'], 'output', 'intersected_bed_files', 'gff_tombo_5mC.bed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tombo_hc_nano = BedTool(tombo_hc_nano_m5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff = BedTool(ph_Pst_104E_gff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:deeppink\"> Intervals. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = m5c_hc_nano[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcontig_000_003\t289\t290\t5mC\t0.071\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = m5c_hc_nano[1:3] # slice does not seem to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.islice object at 0x7f88830d19f8>\n"
     ]
    }
   ],
   "source": [
    "print(features) # bedtool object supports slices but it doesn't show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.071\n",
      "1\n",
      "0.048\n",
      "1\n",
      "0.048\n",
      "1\n",
      "0.091\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "features = m5c_hc_nano[0:4] # need to name features before each loop because the loop consumes the iterator\n",
    "for line in features:       # need a loop to view slice\n",
    "    print(line.score)\n",
    "    print(len(line))        # difference between start and stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hcontig_000_003'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.chrom # only for one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5mC'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.fields[3] # indexed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'evm.model.hcontig_000_003.1'),\n",
       " ('Parent', 'evm.TU.hcontig_000_003.1'),\n",
       " ('locus_tag', 'Pst104E_15928')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing gff file attributes with bedtools\n",
    "interval = anno_ph_gff[1]\n",
    "sorted(interval.attrs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:mediumvioletred\"> Filtering. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to filter\n",
    "def score_filter(feature, L):\n",
    "    \"Returns True if feature is longer than L\"\n",
    "    return float(feature.score) > L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out scores that are zero\n",
    "filtered_tombo_m5c = BED['5mC_tombo_sorted'].filter(score_filter, 0)\n",
    "filtered_tombo_m6a = BED['6mA_tombo_sorted'].filter(score_filter, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try filtering again with the original (manually generated) bed files\n",
    "filtered_tombo_m5c = m5c_tombo.filter(score_filter, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/5mC_hc_tombo_sorted.bed)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tombo_m5c.saveas(hc_tombo_m5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/home/anjuni/methylation_calling/pacbio/output/intersected_bed_files/6mA_hc_tombo_sorted.bed)>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tombo_m6a.saveas(hc_tombo_m6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pybedtools.bedtool.BedTool"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m5c_tombo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pybedtools.bedtool.BedTool"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m5c_hc_nano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orchid\"> Each. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies a function to each line\n",
    "# use output = to save to a file as well\n",
    "# use u=true to to something else\n",
    "# try these out on example_file a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t1\t100\tfeature1\t0\t+\n",
      "chr1\t100\t200\tfeature2\t0\t+\n",
      "chr1\t150\t500\tfeature3\t0\t-\n",
      "chr1\t900\t950\tfeature4\t0\t+\n",
      " \n",
      " chr1\t155\t200\tfeature5\t0\t-\n",
      "chr1\t800\t901\tfeature6\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a, '\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b, u=True) # -u means show the full feature of A, not just the overlapping region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t100\t200\tfeature2\t0\t+\n",
      "chr1\t150\t500\tfeature3\t0\t-\n",
      "chr1\t900\t950\tfeature4\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b) # by default, only the overlapping region is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature2\t0\t+\n",
      "chr1\t155\t200\tfeature3\t0\t-\n",
      "chr1\t900\t901\tfeature4\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b, c=True) # -c ads count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t1\t100\tfeature1\t0\t+\t0\n",
      "chr1\t100\t200\tfeature2\t0\t+\t1\n",
      "chr1\t150\t500\tfeature3\t0\t-\t1\n",
      "chr1\t900\t950\tfeature4\t0\t+\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b, v=True) # like grep -v, -v gives non-overlapping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t1\t100\tfeature1\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b, s=True) # only matching strand features given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature3\t0\t-\n",
      "chr1\t900\t901\tfeature4\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = a.intersect(b, S=True) # only opposite strand features given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature2\t0\t+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:fuchsia\"> Randomisation. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigns a significance value to the overlap between two bed files\n",
    "# randomly shuffle a file many times, each time intersecting with another file and counting intersections.\n",
    "# overlap of original file is compared to empirical distribution of overlaps of shuffled files to get p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes = {'chr1': (0, 1000)} # first, need to set chromosome sizes, so use reference genome fasta for this!\n",
    "a = pybedtools.example_bedtool('a.bed').set_chromsizes(chromsizes) # set the chromosome sizes for the first bed file\n",
    "b = pybedtools.example_bedtool('b.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t1\t100\tfeature1\t0\t+\n",
      " chr1\t100\t200\tfeature2\t0\t+\n",
      " chr1\t150\t500\tfeature3\t0\t-\n",
      " chr1\t900\t950\tfeature4\t0\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature5\t0\t-\n",
      " chr1\t800\t901\tfeature6\t0\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = a.randomintersection(b, iterations=100, shuffle_kwargs={'chrom': True}, debug=True) # set debug=False normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list(results) # normally do 1000 or 10000 randomisations\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 1, 1, 2, 2, 2, 1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = a.randomstats(b, iterations=100, shuffle_kwargs={'chrom': True}, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/a.bed': 4,\n",
      " '/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/b.bed': 2,\n",
      " 'actual': 3,\n",
      " 'file_a': '/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/a.bed',\n",
      " 'file_b': '/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/b.bed',\n",
      " 'frac randomized above actual': 0.01,\n",
      " 'frac randomized below actual': 0.87,\n",
      " 'iterations': 100,\n",
      " 'lower_2.5th': 0.0,\n",
      " 'median randomized': 2.0,\n",
      " 'normalized': 1.5,\n",
      " 'other': 2,\n",
      " 'percentile': 93.5,\n",
      " 'self': 4,\n",
      " 'upper_97.5th': 3.0}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(results_dict) # percentile of actual within the distribution percentiles gives the p-value, normalised is the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: 4\n",
      "other: 2\n",
      "actual: 3\n",
      "median randomized: 2.0\n",
      "normalized: 1.5\n",
      "percentile: 93.5\n"
     ]
    }
   ],
   "source": [
    "keys = ['self', 'other', 'actual', 'median randomized', 'normalized', 'percentile']\n",
    "for key in keys:\n",
    "    print('%s: %s' % (key, results_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a comparison between two sets of features (say, two transcription factors) with 1000 randomizations will have an empirical p-value of < 0.001. That is, out of all the randomizations performed, every single one had fewer intersections than the original. Of course the resolution of the p-value is dependent on the number of randomizations: the lowest nonzero p-value for 10000 iterations will be 0.0001. Getting a non-zero p-value often requires doing more randomizations than is practical (several million to tens of millions).\n",
    "\n",
    "That's where the enrichment score comes in. The randomized intersections typically have a normal distribution, but just in case, we take the median of the randomized intersections and call this the background or control. Then we divide the actual intersections by this median to get an enrichment score.\n",
    "\n",
    "The advantage to using the enrichment score is that it gives nonzero scores for more fine-grained comparison among sets of features without performing impractical amounts of randomization. The first example of its usage that I'm aware of is Negre et al. (2010) PLoS Genet 6(1): e1000814, The downside of this metric is that the numbers are relative, and have their greatest utility for making biological conclusions when used in large matrices of pairwise comparisons.\n",
    "\n",
    "BedTool.randomintersection() and BedTool.randomstats() both use the intersection count method. That is, for each randomization the calculated metric is \"number of intersection events\". An alternative is to compute the Jaccard statistic on each iteration, as implemented in BedTool.naive_jaccard(). The Jaccard statistic (or Jaccard similarity) is the ratio of the intersection over the union, and is introduced in a genomic intersection context in Favorov et al. (2012) PLoS Comput Biol 8(5): e1002529. However, this still has the same p-value resolution limitation, so the actual-divided-by-median approach could be tried here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\"> History. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(a.history) # use the tags given to find an instance of a bedtool, and the functions to recreate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pybedtools.example_bedtool('a.bed')\n",
    ">>> b = pybedtools.example_bedtool('b.bed')\n",
    ">>> c = a.intersect(b)\n",
    ">>> d = c.slop(g=pybedtools.chromsizes('hg19'), b=1)\n",
    ">>> e = d.merge()\n",
    "\n",
    ">>> # this step adds complexity!\n",
    ">>> f = e.subtract(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = f.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[<HistoryStep> BedTool(\"/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/a.bed\").intersect(\"/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/b.bed\", ), parent tag: olljamny, result tag: ildowzuw], <HistoryStep> BedTool(\"/tmp/pybedtools.50k6v2sp.tmp\").slop(g=OrderedDict([('chr1', (0, 249250621)), ('chr2', (0, 243199373)), ('chr3', (0, 198022430)), ('chr4', (0, 191154276)), ('chr5', (0, 180915260)), ('chr6', (0, 171115067)), ('chr7', (0, 159138663)), ('chr8', (0, 146364022)), ('chr9', (0, 141213431)), ('chr10', (0, 135534747)), ('chr11', (0, 135006516)), ('chr12', (0, 133851895)), ('chr13', (0, 115169878)), ('chr14', (0, 107349540)), ('chr15', (0, 102531392)), ('chr16', (0, 90354753)), ('chr17', (0, 81195210)), ('chr18', (0, 78077248)), ('chr19', (0, 59128983)), ('chr20', (0, 63025520)), ('chr21', (0, 48129895)), ('chr22', (0, 51304566)), ('chrX', (0, 155270560)), ('chrY', (0, 59373566)), ('chrM', (0, 16571)), ('chr6_ssto_hap7', (0, 4928567)), ('chr6_mcf_hap5', (0, 4833398)), ('chr6_cox_hap2', (0, 4795371)), ('chr6_mann_hap4', (0, 4683263)), ('chr6_apd_hap1', (0, 4622290)), ('chr6_qbl_hap6', (0, 4611984)), ('chr6_dbb_hap3', (0, 4610396)), ('chr17_ctg5_hap1', (0, 1680828)), ('chr4_ctg9_hap1', (0, 590426)), ('chr1_gl000192_random', (0, 547496)), ('chrUn_gl000225', (0, 211173)), ('chr4_gl000194_random', (0, 191469)), ('chr4_gl000193_random', (0, 189789)), ('chr9_gl000200_random', (0, 187035)), ('chrUn_gl000222', (0, 186861)), ('chrUn_gl000212', (0, 186858)), ('chr7_gl000195_random', (0, 182896)), ('chrUn_gl000223', (0, 180455)), ('chrUn_gl000224', (0, 179693)), ('chrUn_gl000219', (0, 179198)), ('chr17_gl000205_random', (0, 174588)), ('chrUn_gl000215', (0, 172545)), ('chrUn_gl000216', (0, 172294)), ('chrUn_gl000217', (0, 172149)), ('chr9_gl000199_random', (0, 169874)), ('chrUn_gl000211', (0, 166566)), ('chrUn_gl000213', (0, 164239)), ('chrUn_gl000220', (0, 161802)), ('chrUn_gl000218', (0, 161147)), ('chr19_gl000209_random', (0, 159169)), ('chrUn_gl000221', (0, 155397)), ('chrUn_gl000214', (0, 137718)), ('chrUn_gl000228', (0, 129120)), ('chrUn_gl000227', (0, 128374)), ('chr1_gl000191_random', (0, 106433)), ('chr19_gl000208_random', (0, 92689)), ('chr9_gl000198_random', (0, 90085)), ('chr17_gl000204_random', (0, 81310)), ('chrUn_gl000233', (0, 45941)), ('chrUn_gl000237', (0, 45867)), ('chrUn_gl000230', (0, 43691)), ('chrUn_gl000242', (0, 43523)), ('chrUn_gl000243', (0, 43341)), ('chrUn_gl000241', (0, 42152)), ('chrUn_gl000236', (0, 41934)), ('chrUn_gl000240', (0, 41933)), ('chr17_gl000206_random', (0, 41001)), ('chrUn_gl000232', (0, 40652)), ('chrUn_gl000234', (0, 40531)), ('chr11_gl000202_random', (0, 40103)), ('chrUn_gl000238', (0, 39939)), ('chrUn_gl000244', (0, 39929)), ('chrUn_gl000248', (0, 39786)), ('chr8_gl000196_random', (0, 38914)), ('chrUn_gl000249', (0, 38502)), ('chrUn_gl000246', (0, 38154)), ('chr17_gl000203_random', (0, 37498)), ('chr8_gl000197_random', (0, 37175)), ('chrUn_gl000245', (0, 36651)), ('chrUn_gl000247', (0, 36422)), ('chr9_gl000201_random', (0, 36148)), ('chrUn_gl000235', (0, 34474)), ('chrUn_gl000239', (0, 33824)), ('chr21_gl000210_random', (0, 27682)), ('chrUn_gl000231', (0, 27386)), ('chrUn_gl000229', (0, 19913)), ('chrUn_gl000226', (0, 15008)), ('chr18_gl000207_random', (0, 4262))]),b=1), parent tag: ildowzuw, result tag: jmerdczb], <HistoryStep> BedTool(\"/tmp/pybedtools.g6httepk.tmp\").merge(), parent tag: jmerdczb, result tag: jlokosbv], <HistoryStep> BedTool(\"/tmp/pybedtools.lgjwbu5h.tmp\").subtract(\"/home/anjuni/anaconda3/lib/python3.6/site-packages/pybedtools/test/data/b.bed\", ), parent tag: jlokosbv, result tag: qzcrzjoz]\n"
     ]
    }
   ],
   "source": [
    "print(h) # can't really see the steps separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\"> Piping. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x1 = a.intersect(b, u=True)\n",
    ">>> x2 = x1.merge()\n",
    "\n",
    ">>> x3 = a.intersect(b, u=True).merge()\n",
    "\n",
    ">>> x2 == x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = a.intersect(b, u=True).saveas('a-with-b.bed').merge().saveas('a-with-b-merged.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> x4 = a\\\n",
    "... .intersect(b, u=True)\\\n",
    "... .saveas('a-with-b.bed')\\\n",
    "... .merge()\\\n",
    "... .saveas('a-with-b-merged.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x5 = a.intersect(b, u=True) # u only sets the actual parts of a that overlapped with a part of b\n",
    ">>> x6 = a + b                  # this part isn't relevant to methylation since its by each base\n",
    "                                # but it might be useful when comparing patterns of methylation...\n",
    ">>> x5 == x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = a.intersect(b)\n",
    "x5 == x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature2\t0\t+\n",
      " chr1\t155\t200\tfeature3\t0\t-\n",
      " chr1\t900\t901\tfeature4\t0\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "x0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t100\t200\tfeature2\t0\t+\n",
      " chr1\t150\t500\tfeature3\t0\t-\n",
      " chr1\t900\t950\tfeature4\t0\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "x5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x7 = a.intersect(b, v=True) # v gives the full feature of a\n",
    ">>> x8 = a - b\n",
    "\n",
    ">>> x7 == x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x10 = a.intersect(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t155\t200\tfeature2\t0\t+\n",
      " chr1\t155\t200\tfeature3\t0\t-\n",
      " chr1\t900\t901\tfeature4\t0\t+\n",
      " "
     ]
    }
   ],
   "source": [
    "x10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9 = (a + b).merge()\n",
    "x2 == x3 == x4 == x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
